{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "root_dir = \"shopee-product-matching/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попытка разобраться с дата-генераторами\n",
    "\n",
    "Возможно, не тот выходной вектор??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вспомогательный\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size=32, input_size=(224, 224, 3), shuffle=True):\n",
    "        self.df = df.copy()\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = shuffle(self.df)\n",
    "    \n",
    "    def load_image(self, path):\n",
    "        img = load_img(path, target_size=self.input_size)\n",
    "        input_arr = img_to_array(img)\n",
    "        input_arr = input_arr / 255.0\n",
    "        return input_arr \n",
    "    \n",
    "    def load_triplet(self, df, ind):\n",
    "        value = df.iloc[ind,:]\n",
    "        similar = self.df[self.df[\"label_group\"] == value[\"label_group\"]][self.df[\"image\"] != value[\"image\"]]\n",
    "        different = self.df[self.df[\"label_group\"] != value[\"label_group\"]]\n",
    "        \n",
    "        anchor = self.load_image(value[\"image\"])\n",
    "        positive = self.load_image(np.random.choice(similar[\"image\"]))\n",
    "        negative = self.load_image(np.random.choice(different[\"image\"]))\n",
    "            \n",
    "        return(anchor, positive, negative)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        X_batch, y_batch = [], []\n",
    "        for i in range(len(batches)):\n",
    "            a, p, n = self.load_triplet(batches, i)\n",
    "            X_batch.append(a)\n",
    "            y_batch.append([p, n])\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сам хэндлер\n",
    "class DatasetHandler:    \n",
    "    def __init__(self, root_dir, batch_size=32, image_size=(300, 300, 3), shuffle=True):\n",
    "        all_train_df = pd.read_csv(root_dir + \"train.csv\")\n",
    "        all_train_df['image'] = root_dir + 'train_images/' + all_train_df['image']       \n",
    "        \n",
    "        splitter = GroupShuffleSplit(n_splits=2, test_size=0.2, random_state=42)\n",
    "        train_idx, val_idx = next(splitter.split(all_train_df, groups=all_train_df.label_group))\n",
    "        self.train_df = all_train_df.iloc[train_idx]\n",
    "        self.val_df = all_train_df.iloc[val_idx]\n",
    "        \n",
    "        self.image_size = image_size\n",
    "        \n",
    "        self.train_generator = DataGenerator(self.train_df, batch_size, image_size, shuffle)\n",
    "        self.val_generator = DataGenerator(self.val_df, batch_size, image_size, shuffle)\n",
    "        \n",
    "    def get_train_gen(self):\n",
    "        return self.train_generator\n",
    "    \n",
    "    def get_val_gen(self):\n",
    "        return self.val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DatasetHandler(root_dir, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = dh.get_train_gen()\n",
    "vg = dh.get_val_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_triplet(a, p, n):\n",
    "    fig = plt.figure(figsize=(9, 3))\n",
    "    axs = fig.subplots(1, 3)\n",
    "        \n",
    "    def show(ax, image):\n",
    "        ax.imshow(image)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "    show(axs[0], a)\n",
    "    show(axs[1], p)\n",
    "    show(axs[2], n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Старое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:    \n",
    "    def __init__(self, root_dir, image_size=(300, 300)):\n",
    "        all_train_df = pd.read_csv(root_dir + \"train.csv\")\n",
    "        all_train_df['image'] = root_dir + 'train_images/' + all_train_df['image']       \n",
    "        \n",
    "        splitter = GroupShuffleSplit(n_splits=2, test_size=0.2, random_state=42)\n",
    "        train_idx, val_idx = next(splitter.split(all_train_df, groups=all_train_df.label_group))\n",
    "        self.train_df = all_train_df.iloc[train_idx]\n",
    "        self.val_df = all_train_df.iloc[val_idx]\n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.images = self.load_images(all_train_df, True)\n",
    "        \n",
    "    def load_image(self, path):\n",
    "        img = load_img(path, target_size=self.image_size)\n",
    "        input_arr = img_to_array(img)\n",
    "        input_arr = input_arr / 255.0\n",
    "        return input_arr\n",
    "    \n",
    "    def load_images(self, df, verbose = False):\n",
    "        img_dict = {}\n",
    "        for i in range(len(df)):\n",
    "            img_dict[df[\"image\"].iloc[i]] = self.load_image(df[\"image\"].iloc[i])\n",
    "            if verbose:\n",
    "                print(f\"Loaded img {i+1} out of {len(df)}\")\n",
    "        return img_dict\n",
    "        \n",
    "    def load_triplet(self, df, ind, visualize=False):\n",
    "        value = df.iloc[ind,:]\n",
    "        similar = df[(df[\"label_group\"] == value[\"label_group\"]) & (df[\"image\"] != value[\"image\"])]\n",
    "        different = df[df[\"label_group\"] != value[\"label_group\"]]\n",
    "        \n",
    "        anchor = self.images[value[\"image\"]]\n",
    "        positive = self.images[np.random.choice(similar[\"image\"])]\n",
    "        negative = self.images[np.random.choice(different[\"image\"])]\n",
    "        \n",
    "        if visualize:\n",
    "            self.visualize_triplet(anchor, positive, negative)\n",
    "            \n",
    "        return(anchor, positive, negative)  \n",
    "    \n",
    "    def visualize_triplet(self, a, p, n):\n",
    "        fig = plt.figure(figsize=(9, 3))\n",
    "        axs = fig.subplots(1, 3)\n",
    "        \n",
    "        def show(ax, image):\n",
    "            ax.imshow(image)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "        show(axs[0], a)\n",
    "        show(axs[1], p)\n",
    "        show(axs[2], n)\n",
    "        \n",
    "    def get_train_triplets(self):\n",
    "        self.train_df = shuffle(self.train_df)\n",
    "        triplets = []\n",
    "        for i in range(len(self.train_df)):\n",
    "            a, p, n = self.load_triplet(self.train_df, i)\n",
    "            triplets.append([a, p, n])\n",
    "            print(f\"Loaded triplet {i+1} out of {len(self.train_df)}\")\n",
    "        return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуталась в том, какой должен быть вывод.\n",
    "\n",
    "Изображения загружаются вечность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dh = DatasetHandler(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dh.get_train_triplets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_triplet(data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
