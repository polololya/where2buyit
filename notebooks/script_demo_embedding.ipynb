{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import resnet\n",
    "\n",
    "\n",
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return ap_distance, an_distance\n",
    "\n",
    "\n",
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "\n",
    "class EmbeddingModel:\n",
    "    def __init__(self, target_shape):\n",
    "        base_cnn = resnet.ResNet50(\n",
    "            weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n",
    "        )\n",
    "\n",
    "        flatten = layers.Flatten()(base_cnn.output)\n",
    "        dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "        dense1 = layers.BatchNormalization()(dense1)\n",
    "        dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "        dense2 = layers.BatchNormalization()(dense2)\n",
    "        output = layers.Dense(256)(dense2)\n",
    "\n",
    "        self.embedding = Model(base_cnn.input, output, name=\"Embedding\")\n",
    "\n",
    "        trainable = False\n",
    "        for layer in base_cnn.layers:\n",
    "            if layer.name == \"conv5_block1_out\":\n",
    "                trainable = True\n",
    "            layer.trainable = trainable\n",
    "\n",
    "        anchor_input = layers.Input(name=\"anchor\", shape=target_shape + (3,))\n",
    "        positive_input = layers.Input(name=\"positive\", shape=target_shape + (3,))\n",
    "        negative_input = layers.Input(name=\"negative\", shape=target_shape + (3,))\n",
    "\n",
    "        distances = DistanceLayer()(\n",
    "             self.embedding(resnet.preprocess_input(anchor_input)),\n",
    "             self.embedding(resnet.preprocess_input(positive_input)),\n",
    "             self.embedding(resnet.preprocess_input(negative_input)),\n",
    "        ) \n",
    "\n",
    "        self.siamese_network = Model(\n",
    "            inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    "        )\n",
    "\n",
    "    def get_siamese_network(self):\n",
    "        return self.siamese_network\n",
    "\n",
    "    @staticmethod\n",
    "    def train(siamese_network, train_data, val_data):\n",
    "        siamese_model = SiameseModel(siamese_network)\n",
    "        siamese_model.compile(optimizer=optimizers.Adam(0.0001))\n",
    "        siamese_model.fit(train_data, epochs=10, validation_data=val_data)\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"todo\"\"\"\n",
    "\n",
    "    def inference(self):\n",
    "        \"\"\"todo\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from random import choice, sample, randint\n",
    "from tqdm import tqdm\n",
    "\n",
    "FULL_DATASET_FILE = 'Ebay_info.txt'\n",
    "\n",
    "\n",
    "class DatasetHandler:\n",
    "    \"\"\"DataHandler - класс для получения и обработки StandfordDataset для модели основанной на TripletLoss\n",
    "    Attributes:\n",
    "    -----------\n",
    "    dataset_dir : str\n",
    "            путь к папке Standford_Online_Products (Пример: ../Data/Standford_Online_Products)\n",
    "    split_dataset : tuple(int, int)\n",
    "            отношение частей train и test\n",
    "    batch_size : int\n",
    "            количество триплетов в батче\n",
    "    target_shape : tuple(int, int)\n",
    "            размер в который будут переведены изображения\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_dir,\n",
    "                 split_dataset=(0.8, 0.2),\n",
    "                 dataset_part=1,\n",
    "                 batch_size=64,\n",
    "                 target_shape=(400, 400)):\n",
    "\n",
    "        self.__target_shape = target_shape\n",
    "        self.dataset_dir = dataset_dir\n",
    "\n",
    "        full_dataset = pd.read_csv(f'{self.dataset_dir}/{FULL_DATASET_FILE}', sep=' ')\n",
    "        self.__dataset_partitions = split_dataset\n",
    "\n",
    "        self.df_train, self.df_test = self.__split_dataset(full_dataset, dataset_part)\n",
    "\n",
    "    def get_train(self):\n",
    "        return self.df_train\n",
    "    def get_test(self):\n",
    "        return self.df_test\n",
    "        # Train/test triplets\n",
    "    def Train_test_triplets(self,batch_size=64):\n",
    "        tqdm.write(f'Train generating')\n",
    "        train_triplets = self.__generate_triplets(self.df_train)\n",
    "        self.train_dataset = self.__seal_dataset(train_triplets)\n",
    "        self.train_dataset = self.train_dataset.batch(batch_size).prefetch(2)\n",
    "        tqdm.write(f'Test generating')\n",
    "        test_triplets = self.__generate_triplets(self.df_test)\n",
    "        self.test_dataset = self.__seal_dataset(test_triplets)\n",
    "        self.test_dataset = self.test_dataset.batch(batch_size).prefetch(2)\n",
    "        return(self.train_dataset,self.test_dataset)\n",
    "\n",
    "    def __split_dataset(self, data: pd.DataFrame, dataset_part: float):\n",
    "        \"\"\"\n",
    "        Деление всего датасета на train/test в зависимости с dataset_part и split_dataset, переданным в параметры класса\n",
    "        \"\"\"\n",
    "        super_classes = list(data.super_class_id.unique())\n",
    "        df_train = data.copy()\n",
    "        df_test = data.copy()\n",
    "        for super_class in super_classes:\n",
    "            super_class_indexes = list(data.loc[data.super_class_id == super_class].index)\n",
    "            dropped_index = sample(super_class_indexes, int(dataset_part * len(super_class_indexes)))\n",
    "            dropped_index = list(set(super_class_indexes) - set(dropped_index))\n",
    "            train_super_class_indexes = sample(super_class_indexes,\n",
    "                                               int(self.__dataset_partitions[0] * len(super_class_indexes)))\n",
    "\n",
    "            test_super_class_indexes = list(set(super_class_indexes) - set(train_super_class_indexes))\n",
    "\n",
    "            df_train.drop(index=test_super_class_indexes + dropped_index, inplace=True)\n",
    "            df_test.drop(index=train_super_class_indexes + dropped_index, inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    def __form_triplet(self, ind: int, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Формирование триплета. Для выбранного изображения берется изображение из его класса, если такое отсутствует, то\n",
    "        берется из суперласса. Отличное от выбранного изображение берется таким, чтобы оно не было в том же классе, что\n",
    "        и выбранный.\n",
    "        \"\"\"\n",
    "        anchor = data.iloc[ind]\n",
    "        similar_indexes = data.loc[(data.class_id == anchor.class_id) & (data.image_id != anchor.image_id)].index\n",
    "        if len(similar_indexes) == 0:\n",
    "            similar_indexes = data.loc[(data.super_class_id == anchor.super_class_id)].index\n",
    "        positive = data.loc[choice(similar_indexes)]\n",
    "        different_indexes = data.drop(index=data.loc[data.class_id == anchor.class_id].index).index\n",
    "        negative = data.loc[choice(different_indexes)]\n",
    "\n",
    "        return anchor, positive, negative\n",
    "\n",
    "    def __generate_triplets(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Генерация триплетов, на данном этапе хранятся лишь пути к изображениям\n",
    "        \"\"\"\n",
    "        triplets = {'anchors': [], 'positive': [], 'negative': []}\n",
    "        for i in tqdm(range(data.shape[0])):\n",
    "            anchor, positive, negative = self.__form_triplet(i, data)\n",
    "            triplets['anchors'].append(f'{self.dataset_dir}{anchor[\"path\"]}')\n",
    "            triplets['positive'].append(f'{self.dataset_dir}{positive[\"path\"]}')\n",
    "            triplets['negative'].append(f'{self.dataset_dir}{negative[\"path\"]}')\n",
    "        return triplets\n",
    "\n",
    "    def __seal_dataset(self, data: dict):\n",
    "        \"\"\"\n",
    "        Получение триплета из целевого изображения, похожего на него и отличного от него.\n",
    "        \"\"\"\n",
    "        anchor_dataset = tf.data.Dataset.from_tensor_slices(data['anchors'])\n",
    "        positive_dataset = tf.data.Dataset.from_tensor_slices(data['positive'])\n",
    "        negative_dataset = tf.data.Dataset.from_tensor_slices(data['negative'])\n",
    "\n",
    "        triplets_path_dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "        triplets_images_dataset = triplets_path_dataset.map(self.__preprocess_triplets).map(\n",
    "            self.__augmentation_triplets)\n",
    "\n",
    "        return triplets_images_dataset\n",
    "\n",
    "    def __augmentation_triplets(self, anchor, positive, negative):\n",
    "\n",
    "        \"\"\"\n",
    "        Аугментация каждого изображения из триплета\n",
    "        \"\"\"\n",
    "\n",
    "        return (\n",
    "            self.__augmentation_image(anchor),\n",
    "            self.__augmentation_image(positive),\n",
    "            self.__augmentation_image(negative),\n",
    "        )\n",
    "\n",
    "    def __augmentation_image(self, image):\n",
    "\n",
    "        \"\"\"\n",
    "        Аугментация изображения\n",
    "        random_flip_left_right - случайное отражение по оси Y\n",
    "        random_flip_up_down - случайное отражение по оси X\n",
    "        random_brightness - случайное изменение яяркости\n",
    "        random_contrast - случайное изменение контраста\n",
    "        random_saturation -  случайное изменение насыщенности\n",
    "        rot90 - переворот на 90 градусов случайное кол-во раз\n",
    "        \"\"\"\n",
    "\n",
    "        aug_image = tf.image.random_flip_left_right(image)\n",
    "        aug_image = tf.image.random_flip_up_down(aug_image)\n",
    "        aug_image = tf.image.random_brightness(aug_image, max_delta=0.3)\n",
    "        aug_image = tf.image.random_contrast(aug_image, lower=0.6, upper=1)\n",
    "        aug_image = tf.image.random_saturation(aug_image, 0.6, 1)\n",
    "        aug_image = tf.image.rot90(aug_image, k=randint(0, 3))\n",
    "        return aug_image\n",
    "\n",
    "    def preprocess_image(self, filename: tf.Tensor):\n",
    "        \"\"\"\n",
    "        Загрузка изображения, декодирование, перевод значений в числа с плавающей точкой, а также изменение размера\n",
    "        \"\"\"\n",
    "\n",
    "        image_string = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.image.resize(image, self.__target_shape)\n",
    "\n",
    "        return image\n",
    "\n",
    "    @tf.autograph.experimental.do_not_convert\n",
    "    def __preprocess_triplets(self, anchor, positive, negative):\n",
    "        \"\"\"\n",
    "        Метод для обработки каждого изображения из триплета\n",
    "        \"\"\"\n",
    "\n",
    "        return (\n",
    "            self.__preprocess_image(anchor),\n",
    "            self.__preprocess_image(positive),\n",
    "            self.__preprocess_image(negative),\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "    Метод для поучения установленного размера изображений\n",
    "    \"\"\"\n",
    "\n",
    "    def get_target_shape(self):\n",
    "        return self.__target_shape\n",
    "\n",
    "    \"\"\"\n",
    "    Метод ждя получения train dataset\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Path=\"C:/Users/user/Desktop/imp/stag2/\"#только с полным путем у меня работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data=dataset_handler.Train_test_triplets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "embedding_model=tf.keras.models.load_model(Main_Path+\"embedding_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=Main_Path+'Stanford_Online_Products'\n",
    "dataset_handler=DatasetHandler(dataset_dir)\n",
    "test=dataset_handler.get_test()\n",
    "test_model =EmbeddingModel(target_shape=dataset_handler.get_target_shape())\n",
    "test.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "embeddings=pd.DataFrame([])\n",
    "n=len(test)\n",
    "#n=10\n",
    "for i in range (n):#работает очень медленно, но я не знаю как оптимизировать\n",
    "    #print('C:/Users/user/Desktop/imp/stag2/Stanford_Online_Products/'+test.iloc[i,-1])\n",
    "    ret=tf.Variable(dataset_dir+'/'+test.iloc[i,-1],dtype=tf.string)\n",
    "    #print(ret)\n",
    "    #print(__preprocess_image(ret))\n",
    "    im=dataset_handler.preprocess_image(ret)\n",
    "    embeddings =embeddings.append(pd.DataFrame(test_model.embedding(tf.expand_dims(im, axis=0)).numpy()),ignore_index=True)\n",
    "    #test_model. если бы была бы embedding_model, то было бы embedding_model.\n",
    "df=embeddings.join(test.iloc[:n,-3:])\n",
    "df.columns = df.columns.astype (str)\n",
    "df.to_parquet('df_emb',engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>class_id</th>\n",
       "      <th>super_class_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.085142</td>\n",
       "      <td>2.263834</td>\n",
       "      <td>-0.885343</td>\n",
       "      <td>1.836391</td>\n",
       "      <td>-1.162681</td>\n",
       "      <td>-0.809887</td>\n",
       "      <td>0.831483</td>\n",
       "      <td>0.599229</td>\n",
       "      <td>-1.235901</td>\n",
       "      <td>-0.049218</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126033</td>\n",
       "      <td>0.377122</td>\n",
       "      <td>1.116078</td>\n",
       "      <td>1.337602</td>\n",
       "      <td>0.849155</td>\n",
       "      <td>-1.622025</td>\n",
       "      <td>0.011362</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111085122871_1.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.288717</td>\n",
       "      <td>2.206600</td>\n",
       "      <td>-1.110308</td>\n",
       "      <td>1.920529</td>\n",
       "      <td>-0.854689</td>\n",
       "      <td>-0.343830</td>\n",
       "      <td>0.883807</td>\n",
       "      <td>0.728295</td>\n",
       "      <td>-0.981223</td>\n",
       "      <td>0.094597</td>\n",
       "      <td>...</td>\n",
       "      <td>2.286892</td>\n",
       "      <td>-0.117384</td>\n",
       "      <td>0.656719</td>\n",
       "      <td>1.288287</td>\n",
       "      <td>0.557438</td>\n",
       "      <td>-1.345682</td>\n",
       "      <td>0.175416</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111265328556_4.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.196385</td>\n",
       "      <td>2.095917</td>\n",
       "      <td>-1.520651</td>\n",
       "      <td>1.525144</td>\n",
       "      <td>-1.129098</td>\n",
       "      <td>-0.837190</td>\n",
       "      <td>0.725680</td>\n",
       "      <td>0.675833</td>\n",
       "      <td>-1.076203</td>\n",
       "      <td>0.041220</td>\n",
       "      <td>...</td>\n",
       "      <td>2.077071</td>\n",
       "      <td>-0.269411</td>\n",
       "      <td>1.009172</td>\n",
       "      <td>1.579502</td>\n",
       "      <td>0.765996</td>\n",
       "      <td>-1.766425</td>\n",
       "      <td>-0.367796</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111265328556_6.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.202026</td>\n",
       "      <td>1.984765</td>\n",
       "      <td>-0.719857</td>\n",
       "      <td>1.333729</td>\n",
       "      <td>-1.253502</td>\n",
       "      <td>-0.486325</td>\n",
       "      <td>0.618138</td>\n",
       "      <td>0.398293</td>\n",
       "      <td>-1.160885</td>\n",
       "      <td>0.438762</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302423</td>\n",
       "      <td>-0.056354</td>\n",
       "      <td>0.943287</td>\n",
       "      <td>1.618322</td>\n",
       "      <td>0.441846</td>\n",
       "      <td>-0.972010</td>\n",
       "      <td>0.076793</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111265348817_2.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018245</td>\n",
       "      <td>2.131875</td>\n",
       "      <td>-0.822429</td>\n",
       "      <td>1.775731</td>\n",
       "      <td>-1.151801</td>\n",
       "      <td>-0.687859</td>\n",
       "      <td>0.592101</td>\n",
       "      <td>0.729311</td>\n",
       "      <td>-1.227695</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>...</td>\n",
       "      <td>2.170035</td>\n",
       "      <td>-0.032085</td>\n",
       "      <td>0.965099</td>\n",
       "      <td>1.746426</td>\n",
       "      <td>0.802978</td>\n",
       "      <td>-1.460227</td>\n",
       "      <td>-0.450101</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111375616144_1.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.161554</td>\n",
       "      <td>1.965031</td>\n",
       "      <td>-1.204765</td>\n",
       "      <td>1.795040</td>\n",
       "      <td>-1.166557</td>\n",
       "      <td>-0.501812</td>\n",
       "      <td>0.895801</td>\n",
       "      <td>0.637940</td>\n",
       "      <td>-1.066792</td>\n",
       "      <td>0.187091</td>\n",
       "      <td>...</td>\n",
       "      <td>2.450968</td>\n",
       "      <td>0.061530</td>\n",
       "      <td>0.956310</td>\n",
       "      <td>1.411432</td>\n",
       "      <td>0.832268</td>\n",
       "      <td>-1.613709</td>\n",
       "      <td>0.332984</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111476691561_5.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.416950</td>\n",
       "      <td>2.344188</td>\n",
       "      <td>-0.906669</td>\n",
       "      <td>1.560650</td>\n",
       "      <td>-1.334940</td>\n",
       "      <td>-0.673229</td>\n",
       "      <td>0.586341</td>\n",
       "      <td>0.766725</td>\n",
       "      <td>-0.541149</td>\n",
       "      <td>-0.213924</td>\n",
       "      <td>...</td>\n",
       "      <td>1.598669</td>\n",
       "      <td>0.171077</td>\n",
       "      <td>0.241735</td>\n",
       "      <td>1.178248</td>\n",
       "      <td>0.673523</td>\n",
       "      <td>-1.590650</td>\n",
       "      <td>0.360401</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111476691561_9.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.233066</td>\n",
       "      <td>1.984723</td>\n",
       "      <td>-1.523679</td>\n",
       "      <td>1.706785</td>\n",
       "      <td>-1.199485</td>\n",
       "      <td>-0.460579</td>\n",
       "      <td>1.060521</td>\n",
       "      <td>0.725634</td>\n",
       "      <td>-1.059003</td>\n",
       "      <td>-0.133839</td>\n",
       "      <td>...</td>\n",
       "      <td>2.178601</td>\n",
       "      <td>-0.127449</td>\n",
       "      <td>1.177631</td>\n",
       "      <td>1.272139</td>\n",
       "      <td>0.571926</td>\n",
       "      <td>-1.800723</td>\n",
       "      <td>-0.039683</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111502876121_4.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.087598</td>\n",
       "      <td>1.791137</td>\n",
       "      <td>-0.584348</td>\n",
       "      <td>1.810316</td>\n",
       "      <td>-1.511694</td>\n",
       "      <td>0.214525</td>\n",
       "      <td>0.818769</td>\n",
       "      <td>0.736485</td>\n",
       "      <td>-1.107280</td>\n",
       "      <td>0.149841</td>\n",
       "      <td>...</td>\n",
       "      <td>2.042173</td>\n",
       "      <td>-0.197772</td>\n",
       "      <td>1.251872</td>\n",
       "      <td>0.979754</td>\n",
       "      <td>0.455892</td>\n",
       "      <td>-1.094271</td>\n",
       "      <td>0.194153</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111502876121_8.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.123475</td>\n",
       "      <td>2.057287</td>\n",
       "      <td>-0.632529</td>\n",
       "      <td>1.940392</td>\n",
       "      <td>-1.289135</td>\n",
       "      <td>-0.534737</td>\n",
       "      <td>1.011053</td>\n",
       "      <td>0.923829</td>\n",
       "      <td>-1.224715</td>\n",
       "      <td>-0.239091</td>\n",
       "      <td>...</td>\n",
       "      <td>1.954331</td>\n",
       "      <td>0.413944</td>\n",
       "      <td>0.997784</td>\n",
       "      <td>1.598377</td>\n",
       "      <td>0.662749</td>\n",
       "      <td>-1.817938</td>\n",
       "      <td>-0.122325</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>bicycle_final/111579336659_3.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.085142  2.263834 -0.885343  1.836391 -1.162681 -0.809887  0.831483   \n",
       "1  0.288717  2.206600 -1.110308  1.920529 -0.854689 -0.343830  0.883807   \n",
       "2 -0.196385  2.095917 -1.520651  1.525144 -1.129098 -0.837190  0.725680   \n",
       "3  0.202026  1.984765 -0.719857  1.333729 -1.253502 -0.486325  0.618138   \n",
       "4  0.018245  2.131875 -0.822429  1.775731 -1.151801 -0.687859  0.592101   \n",
       "5  0.161554  1.965031 -1.204765  1.795040 -1.166557 -0.501812  0.895801   \n",
       "6  0.416950  2.344188 -0.906669  1.560650 -1.334940 -0.673229  0.586341   \n",
       "7 -0.233066  1.984723 -1.523679  1.706785 -1.199485 -0.460579  1.060521   \n",
       "8 -0.087598  1.791137 -0.584348  1.810316 -1.511694  0.214525  0.818769   \n",
       "9  0.123475  2.057287 -0.632529  1.940392 -1.289135 -0.534737  1.011053   \n",
       "\n",
       "          7         8         9  ...       249       250       251       252  \\\n",
       "0  0.599229 -1.235901 -0.049218  ...  2.126033  0.377122  1.116078  1.337602   \n",
       "1  0.728295 -0.981223  0.094597  ...  2.286892 -0.117384  0.656719  1.288287   \n",
       "2  0.675833 -1.076203  0.041220  ...  2.077071 -0.269411  1.009172  1.579502   \n",
       "3  0.398293 -1.160885  0.438762  ...  2.302423 -0.056354  0.943287  1.618322   \n",
       "4  0.729311 -1.227695  0.014845  ...  2.170035 -0.032085  0.965099  1.746426   \n",
       "5  0.637940 -1.066792  0.187091  ...  2.450968  0.061530  0.956310  1.411432   \n",
       "6  0.766725 -0.541149 -0.213924  ...  1.598669  0.171077  0.241735  1.178248   \n",
       "7  0.725634 -1.059003 -0.133839  ...  2.178601 -0.127449  1.177631  1.272139   \n",
       "8  0.736485 -1.107280  0.149841  ...  2.042173 -0.197772  1.251872  0.979754   \n",
       "9  0.923829 -1.224715 -0.239091  ...  1.954331  0.413944  0.997784  1.598377   \n",
       "\n",
       "        253       254       255  class_id  super_class_id  \\\n",
       "0  0.849155 -1.622025  0.011362         1               1   \n",
       "1  0.557438 -1.345682  0.175416         2               1   \n",
       "2  0.765996 -1.766425 -0.367796         2               1   \n",
       "3  0.441846 -0.972010  0.076793         3               1   \n",
       "4  0.802978 -1.460227 -0.450101         4               1   \n",
       "5  0.832268 -1.613709  0.332984         6               1   \n",
       "6  0.673523 -1.590650  0.360401         6               1   \n",
       "7  0.571926 -1.800723 -0.039683         7               1   \n",
       "8  0.455892 -1.094271  0.194153         7               1   \n",
       "9  0.662749 -1.817938 -0.122325         9               1   \n",
       "\n",
       "                               path  \n",
       "0  bicycle_final/111085122871_1.JPG  \n",
       "1  bicycle_final/111265328556_4.JPG  \n",
       "2  bicycle_final/111265328556_6.JPG  \n",
       "3  bicycle_final/111265348817_2.JPG  \n",
       "4  bicycle_final/111375616144_1.JPG  \n",
       "5  bicycle_final/111476691561_5.JPG  \n",
       "6  bicycle_final/111476691561_9.JPG  \n",
       "7  bicycle_final/111502876121_4.JPG  \n",
       "8  bicycle_final/111502876121_8.JPG  \n",
       "9  bicycle_final/111579336659_3.JPG  \n",
       "\n",
       "[10 rows x 259 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in c:\\users\\user\\anaconda3\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: cramjam>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastparquet) (2.3.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastparquet) (1.2.5)\n",
      "Requirement already satisfied: thrift>=0.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastparquet) (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastparquet) (1.19.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastparquet) (0.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->fastparquet) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->fastparquet) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->fastparquet) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet\n",
    "df.to_parquet('df_emb',engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
